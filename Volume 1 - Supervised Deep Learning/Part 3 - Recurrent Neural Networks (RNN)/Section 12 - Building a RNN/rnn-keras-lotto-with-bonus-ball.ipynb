{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import usual suspects\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>45</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>54</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5\n",
       "0   8  13  26  35  45  51\n",
       "1   1  15  24  31  34  44\n",
       "2   3   8  29  30  31  49\n",
       "3  21  25  39  50  54  59\n",
       "4  15  19  32  38  47  50"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing  the training set\n",
    "pd_training_set = pd.read_csv('Lottery_NY_Lotto_Winning_Numbers__Beginning_2001_without_bonus.csv', header=None)\n",
    "pd_training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Set\n",
    "# now add each column of six rows into next 6 rows of first column\n",
    "two_dim_lotto_array_train = []\n",
    "# take 300 rows less from total for testing and rest use for training\n",
    "for col in pd_training_set.iloc[:-300,:].values:\n",
    "#     print (col)\n",
    "    for row in col:\n",
    "        two_dim_lotto_array_train.append([row])\n",
    "#         print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(7968, 1)\n",
      "[[ 8]\n",
      " [13]\n",
      " [26]\n",
      " ..., \n",
      " [29]\n",
      " [46]\n",
      " [50]]\n"
     ]
    }
   ],
   "source": [
    "# convert python list into numpy array\n",
    "training_set_val = np.array(two_dim_lotto_array_train, ndmin=2)\n",
    "\n",
    "print (type(training_set_val))\n",
    "print (training_set_val.ndim)\n",
    "print (training_set_val.shape)\n",
    "print (training_set_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.13559322]\n",
      " [ 0.22033898]\n",
      " [ 0.44067797]\n",
      " ..., \n",
      " [ 0.49152542]\n",
      " [ 0.77966102]\n",
      " [ 0.84745763]]\n",
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(7968, 1)\n"
     ]
    }
   ],
   "source": [
    "# Now, let's do normalization\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# sc = MinMaxScaler()\n",
    "# # Accuracy: 0.0317802805365\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "sc = MaxAbsScaler()\n",
    "#  Accuracy: 0.0293846626395\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "# sc = RobustScaler()\n",
    "# # Accuracy: 0.0377802805365\n",
    "\n",
    "\n",
    "training_set = sc.fit_transform(training_set_val)\n",
    "print (training_set)\n",
    "print (type(training_set))\n",
    "print (training_set.ndim)\n",
    "print (training_set.shape)\n",
    "\n",
    "# ALSO TRY STANDARDIZATION INSTEAD OF NORMALIZATION\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "\n",
    "# training_set = sc.fit_transform(training_set_val)\n",
    "# print (training_set)\n",
    "# print (type(training_set))\n",
    "# print (training_set.ndim)\n",
    "# print (training_set.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data structure with 60 timesteps and t+1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, 7968):\n",
    "    X_train.append(training_set[i-60:i, 0])\n",
    "    y_train.append(training_set[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.13559322]\n",
      " [ 0.22033898]\n",
      " [ 0.44067797]\n",
      " ..., \n",
      " [ 0.3220339 ]\n",
      " [ 0.49152542]\n",
      " [ 0.77966102]]\n"
     ]
    }
   ],
   "source": [
    "# # IMPORTANT Now we are setting X_train and y_train\n",
    "# # X_train is time at 0 value and y_train is time at +1 value\n",
    "# X_train = training_set[0:7967]\n",
    "# print (X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22033898]\n",
      " [ 0.44067797]\n",
      " [ 0.59322034]\n",
      " ..., \n",
      " [ 0.49152542]\n",
      " [ 0.77966102]\n",
      " [ 0.84745763]]\n"
     ]
    }
   ],
   "source": [
    "# # y_train is time+1 value\n",
    "# y_train = training_set[1:7968]\n",
    "# print (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.13559322]\n",
      "  [ 0.22033898]\n",
      "  [ 0.44067797]\n",
      "  ..., \n",
      "  [ 0.59322034]\n",
      "  [ 0.69491525]\n",
      "  [ 0.83050847]]\n",
      "\n",
      " [[ 0.22033898]\n",
      "  [ 0.44067797]\n",
      "  [ 0.59322034]\n",
      "  ..., \n",
      "  [ 0.69491525]\n",
      "  [ 0.83050847]\n",
      "  [ 0.08474576]]\n",
      "\n",
      " [[ 0.44067797]\n",
      "  [ 0.59322034]\n",
      "  [ 0.76271186]\n",
      "  ..., \n",
      "  [ 0.83050847]\n",
      "  [ 0.08474576]\n",
      "  [ 0.13559322]]\n",
      "\n",
      " ..., \n",
      " [[ 0.79661017]\n",
      "  [ 0.83050847]\n",
      "  [ 0.96610169]\n",
      "  ..., \n",
      "  [ 0.03389831]\n",
      "  [ 0.20338983]\n",
      "  [ 0.3220339 ]]\n",
      "\n",
      " [[ 0.83050847]\n",
      "  [ 0.96610169]\n",
      "  [ 0.15254237]\n",
      "  ..., \n",
      "  [ 0.20338983]\n",
      "  [ 0.3220339 ]\n",
      "  [ 0.49152542]]\n",
      "\n",
      " [[ 0.96610169]\n",
      "  [ 0.15254237]\n",
      "  [ 0.16949153]\n",
      "  ..., \n",
      "  [ 0.3220339 ]\n",
      "  [ 0.49152542]\n",
      "  [ 0.77966102]]]\n"
     ]
    }
   ],
   "source": [
    "# Now, Reshaping for keras before training, as it requires 3 dimenions\n",
    "\n",
    "# changing from 2 to 3 dimension array, by addding time step as 3rd dimension\n",
    "# corresponds to (batch_size, timesteps, input_dim)\n",
    "# X_train = np.reshape(X_train,(7967,1,1))\n",
    "\n",
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "print (X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Initializing the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the Keras liabraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regressor bassed upon sequential RNN\n",
    "# classifier = Sequential()\n",
    "# classifier.add(LSTM(units=10, activation='sigmoid', input_shape=(None, 1)))\n",
    "# classifier.add(Dense(units=1))\n",
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units=4, activation='sigmoid', input_shape=(None, 1), return_sequences = True))\n",
    "regressor.add(LSTM(units=4, activation='sigmoid', return_sequences = True))\n",
    "regressor.add(LSTM(units=4, activation='sigmoid', return_sequences = True))\n",
    "regressor.add(LSTM(units=4, activation='sigmoid'))\n",
    "regressor.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, let' compile our RNN regressor\n",
    "# classifier.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "regressor.compile(optimizer='rmsprop', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7908/7908 [==============================] - 102s - loss: 0.0868   \n",
      "Epoch 2/50\n",
      "7908/7908 [==============================] - 104s - loss: 0.0829   \n",
      "Epoch 3/50\n",
      "7908/7908 [==============================] - 100s - loss: 0.0829   \n",
      "Epoch 4/50\n",
      "7908/7908 [==============================] - 98s - loss: 0.0829    \n",
      "Epoch 5/50\n",
      "6432/7908 [=======================>......] - ETA: 18s - loss: 0.0833"
     ]
    }
   ],
   "source": [
    "regressor.fit(X_train ,y_train, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Making Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing Set\n",
    "# now add each column of six rows into next 6 rows of first column\n",
    "two_dim_lotto_array_test = []\n",
    "# take all rows less from total for testing and rest use for training\n",
    "for col in pd_training_set.iloc[:,:].values:\n",
    "#     print (col)\n",
    "    for row in col:\n",
    "        two_dim_lotto_array_test.append([row])\n",
    "#         print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(9768, 1)\n",
      "[[ 8]\n",
      " [13]\n",
      " [26]\n",
      " ..., \n",
      " [17]\n",
      " [26]\n",
      " [55]]\n"
     ]
    }
   ],
   "source": [
    "# convert python list into numpy array\n",
    "testing_set_val = np.array(two_dim_lotto_array_test, ndmin=2)\n",
    "\n",
    "print (type(testing_set_val))\n",
    "print (testing_set_val.ndim)\n",
    "print (testing_set_val.shape)\n",
    "print (testing_set_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(9768, 1)\n"
     ]
    }
   ],
   "source": [
    "# NOw let's take only open price of stock\n",
    "# if we choose pd_training_set.iloc[:,1] It will be only 1 dim pandas series\n",
    "# however, we need 2 dimension, so\n",
    "real_lotto_numbers = testing_set_val\n",
    "print (type(real_lotto_numbers))\n",
    "print (real_lotto_numbers.ndim)\n",
    "print (real_lotto_numbers.shape)\n",
    "# print (real_lotto_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(9767, 1)\n",
      "[[ 0.13559322]\n",
      " [ 0.22033898]\n",
      " [ 0.44067797]\n",
      " ..., \n",
      " [ 0.20338983]\n",
      " [ 0.28813559]\n",
      " [ 0.44067797]]\n"
     ]
    }
   ],
   "source": [
    "X_test = real_lotto_numbers[0:9767]\n",
    "X_test = sc.fit_transform(X_test)\n",
    "print (type(X_test))\n",
    "print (X_test.ndim)\n",
    "print (X_test.shape)\n",
    "print (X_test)\n",
    "# in the end inverse fit transform to get normal stock open price back\n",
    "# X_test = real_lotto_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13]\n",
      " [26]\n",
      " [35]\n",
      " ..., \n",
      " [17]\n",
      " [26]\n",
      " [55]]\n",
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(9767, 1)\n",
      "[[13]\n",
      " [26]\n",
      " [35]\n",
      " ..., \n",
      " [17]\n",
      " [26]\n",
      " [55]]\n"
     ]
    }
   ],
   "source": [
    "# same for X_test\n",
    "y_test = real_lotto_numbers[1:9768]\n",
    "print (y_test)\n",
    "print (type(y_test))\n",
    "print (y_test.ndim)\n",
    "print (y_test.shape)\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "3\n",
      "(9767, 1, 1)\n",
      "[[[ 0.13559322]]\n",
      "\n",
      " [[ 0.22033898]]\n",
      "\n",
      " [[ 0.44067797]]\n",
      "\n",
      " ..., \n",
      " [[ 0.20338983]]\n",
      "\n",
      " [[ 0.28813559]]\n",
      "\n",
      " [[ 0.44067797]]]\n"
     ]
    }
   ],
   "source": [
    "# Reshaping\n",
    "\n",
    "# chaging from 2 to 3 dimension array, by addding time step as 3rd dimension\n",
    "# corresponds to (batch_size, timesteps, input_dim)\n",
    "test_inputs = np.reshape(X_test,(9767,1,1))\n",
    "print (type(test_inputs))\n",
    "print (test_inputs.ndim)\n",
    "print (test_inputs.shape)\n",
    "print (test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pankajmathur/anaconda/envs/keras-playground/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2094: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(9767, 1)\n",
      "[[ 0.37335977]\n",
      " [ 0.41680336]\n",
      " [ 0.50441271]\n",
      " ..., \n",
      " [ 0.4085049 ]\n",
      " [ 0.44783846]\n",
      " [ 0.50441271]]\n"
     ]
    }
   ],
   "source": [
    "# Now, let's predict\n",
    "y_predicted = regressor.predict(test_inputs)\n",
    "print (type(y_predicted))\n",
    "print (y_predicted.ndim)\n",
    "print (y_predicted.shape)\n",
    "print (y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(9767, 1)\n",
      "[[ 22.]\n",
      " [ 25.]\n",
      " [ 30.]\n",
      " ..., \n",
      " [ 24.]\n",
      " [ 26.]\n",
      " [ 30.]]\n",
      "[[13]\n",
      " [26]\n",
      " [35]\n",
      " ..., \n",
      " [17]\n",
      " [26]\n",
      " [55]]\n"
     ]
    }
   ],
   "source": [
    "# inverse scaled values to get real stock price\n",
    "predicted_lotto_numbers = np.around(sc.inverse_transform(y_predicted))\n",
    "# predicted_lotto_numbers = sc.transform(y_predicted)\n",
    "# predicted_lotto_numbers = y_predicted\n",
    "print (type(predicted_lotto_numbers))\n",
    "print (predicted_lotto_numbers.ndim)\n",
    "print (predicted_lotto_numbers.shape)\n",
    "print (predicted_lotto_numbers)\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0247773113546\n"
     ]
    }
   ],
   "source": [
    "true_predictions = predicted_lotto_numbers == y_test\n",
    "print (\"Accuracy:\", np.sum(true_predictions)/np.size(true_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part 4: Let's Visualize the results\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11dc2fef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(real_lotto_numbers, color='red', label = 'Real Lotto Numbers')\n",
    "plt.plot(predicted_lotto_numbers, color='blue', label = 'Predicted Lotto Numbers')\n",
    "plt.title('Lotto Numbers Prediction')\n",
    "plt.xlabel('Lotto Results')\n",
    "plt.ylabel('Lotto Numbers')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(9768, 1)\n",
      "[[ 0.13559322]\n",
      " [ 0.22033898]\n",
      " [ 0.44067797]\n",
      " ..., \n",
      " [ 0.28813559]\n",
      " [ 0.44067797]\n",
      " [ 0.93220339]]\n"
     ]
    }
   ],
   "source": [
    "X_sample = testing_set_val\n",
    "X_sample = sc.fit_transform(X_sample)\n",
    "print (type(X_sample))\n",
    "print (X_sample.ndim)\n",
    "print (X_sample.shape)\n",
    "print (X_sample)\n",
    "# in the end inverse fit transform to get normal stock open price back\n",
    "# X_test = real_lotto_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "3\n",
      "(9768, 1, 1)\n",
      "[[[ 0.13559322]]\n",
      "\n",
      " [[ 0.22033898]]\n",
      "\n",
      " [[ 0.44067797]]\n",
      "\n",
      " ..., \n",
      " [[ 0.28813559]]\n",
      "\n",
      " [[ 0.44067797]]\n",
      "\n",
      " [[ 0.93220339]]]\n"
     ]
    }
   ],
   "source": [
    "# Reshaping\n",
    "\n",
    "# chaging from 2 to 3 dimension array, by addding time step as 3rd dimension\n",
    "# corresponds to (batch_size, timesteps, input_dim)\n",
    "sample_inputs = np.reshape(X_sample,(9768,1,1))\n",
    "print (type(sample_inputs))\n",
    "print (sample_inputs.ndim)\n",
    "print (sample_inputs.shape)\n",
    "print (sample_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(9768, 1)\n",
      "[[ 0.37335977]\n",
      " [ 0.41680336]\n",
      " [ 0.50441271]\n",
      " ..., \n",
      " [ 0.44783846]\n",
      " [ 0.50441271]\n",
      " [ 0.59640855]]\n"
     ]
    }
   ],
   "source": [
    "# Now, let's predict\n",
    "y_sample = regressor.predict(sample_inputs)\n",
    "print (type(y_sample))\n",
    "print (y_sample.ndim)\n",
    "print (y_sample.shape)\n",
    "print (y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(9768, 1)\n",
      "[[ 22.]\n",
      " [ 25.]\n",
      " [ 30.]\n",
      " ..., \n",
      " [ 26.]\n",
      " [ 30.]\n",
      " [ 35.]]\n"
     ]
    }
   ],
   "source": [
    "# inverse scaled values to get real stock price\n",
    "sample_lotto_numbers = np.around(sc.inverse_transform(y_sample))\n",
    "print (type(sample_lotto_numbers))\n",
    "print (sample_lotto_numbers.ndim)\n",
    "print (sample_lotto_numbers.shape)\n",
    "print (sample_lotto_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_lotto_numbers</th>\n",
       "      <th>sample_lotto_numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9168</th>\n",
       "      <td>16</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9169</th>\n",
       "      <td>18</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9170</th>\n",
       "      <td>26</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171</th>\n",
       "      <td>44</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9172</th>\n",
       "      <td>49</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9173</th>\n",
       "      <td>51</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9174</th>\n",
       "      <td>5</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9175</th>\n",
       "      <td>12</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9176</th>\n",
       "      <td>18</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9177</th>\n",
       "      <td>33</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9178</th>\n",
       "      <td>56</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9179</th>\n",
       "      <td>57</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9180</th>\n",
       "      <td>8</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9181</th>\n",
       "      <td>30</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9182</th>\n",
       "      <td>31</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9183</th>\n",
       "      <td>32</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9184</th>\n",
       "      <td>36</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9185</th>\n",
       "      <td>49</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9186</th>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9187</th>\n",
       "      <td>8</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9188</th>\n",
       "      <td>25</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9189</th>\n",
       "      <td>43</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9190</th>\n",
       "      <td>47</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9191</th>\n",
       "      <td>58</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9192</th>\n",
       "      <td>19</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9193</th>\n",
       "      <td>26</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9194</th>\n",
       "      <td>42</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9195</th>\n",
       "      <td>47</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9196</th>\n",
       "      <td>49</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9197</th>\n",
       "      <td>59</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9738</th>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>4</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>16</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>25</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9742</th>\n",
       "      <td>29</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9743</th>\n",
       "      <td>56</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744</th>\n",
       "      <td>14</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9745</th>\n",
       "      <td>15</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9746</th>\n",
       "      <td>21</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9747</th>\n",
       "      <td>23</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9748</th>\n",
       "      <td>41</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9749</th>\n",
       "      <td>50</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>4</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>15</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9752</th>\n",
       "      <td>24</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9753</th>\n",
       "      <td>33</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9754</th>\n",
       "      <td>37</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>58</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9756</th>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9757</th>\n",
       "      <td>10</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9758</th>\n",
       "      <td>38</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9759</th>\n",
       "      <td>50</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9760</th>\n",
       "      <td>53</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9761</th>\n",
       "      <td>57</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9762</th>\n",
       "      <td>4</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9763</th>\n",
       "      <td>7</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9764</th>\n",
       "      <td>12</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9765</th>\n",
       "      <td>17</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9766</th>\n",
       "      <td>26</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9767</th>\n",
       "      <td>55</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      real_lotto_numbers  sample_lotto_numbers\n",
       "9168                  16                  26.0\n",
       "9169                  18                  27.0\n",
       "9170                  26                  30.0\n",
       "9171                  44                  34.0\n",
       "9172                  49                  34.0\n",
       "9173                  51                  35.0\n",
       "9174                   5                  20.0\n",
       "9175                  12                  24.0\n",
       "9176                  18                  27.0\n",
       "9177                  33                  32.0\n",
       "9178                  56                  35.0\n",
       "9179                  57                  35.0\n",
       "9180                   8                  22.0\n",
       "9181                  30                  31.0\n",
       "9182                  31                  31.0\n",
       "9183                  32                  31.0\n",
       "9184                  36                  32.0\n",
       "9185                  49                  34.0\n",
       "9186                   3                  19.0\n",
       "9187                   8                  22.0\n",
       "9188                  25                  29.0\n",
       "9189                  43                  34.0\n",
       "9190                  47                  34.0\n",
       "9191                  58                  36.0\n",
       "9192                  19                  27.0\n",
       "9193                  26                  30.0\n",
       "9194                  42                  33.0\n",
       "9195                  47                  34.0\n",
       "9196                  49                  34.0\n",
       "9197                  59                  36.0\n",
       "...                  ...                   ...\n",
       "9738                   1                  18.0\n",
       "9739                   4                  20.0\n",
       "9740                  16                  26.0\n",
       "9741                  25                  29.0\n",
       "9742                  29                  31.0\n",
       "9743                  56                  35.0\n",
       "9744                  14                  25.0\n",
       "9745                  15                  26.0\n",
       "9746                  21                  28.0\n",
       "9747                  23                  29.0\n",
       "9748                  41                  33.0\n",
       "9749                  50                  35.0\n",
       "9750                   4                  20.0\n",
       "9751                  15                  26.0\n",
       "9752                  24                  29.0\n",
       "9753                  33                  32.0\n",
       "9754                  37                  33.0\n",
       "9755                  58                  36.0\n",
       "9756                   2                  19.0\n",
       "9757                  10                  23.0\n",
       "9758                  38                  33.0\n",
       "9759                  50                  35.0\n",
       "9760                  53                  35.0\n",
       "9761                  57                  35.0\n",
       "9762                   4                  20.0\n",
       "9763                   7                  21.0\n",
       "9764                  12                  24.0\n",
       "9765                  17                  26.0\n",
       "9766                  26                  30.0\n",
       "9767                  55                  35.0\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_shape = real_lotto_numbers.reshape((11396))\n",
    "# print (type(new_shape))\n",
    "# print (new_shape.ndim)\n",
    "# print (new_shape.shape)\n",
    "# print (new_shape)\n",
    "                           \n",
    "real_lotto_numbers_df = pd.Series(real_lotto_numbers.reshape((9768)), name='real_lotto_numbers')\n",
    "sample_lotto_numbers_df = pd.Series(sample_lotto_numbers.reshape((9768)), name='sample_lotto_numbers')\n",
    "comparison_df = pd.concat([real_lotto_numbers_df, sample_lotto_numbers_df], axis=1)\n",
    "comparison_df.tail(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
